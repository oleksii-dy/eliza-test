{"version":3,"sources":["../src/index.ts"],"sourcesContent":["import type { ObjectGenerationParams, Plugin, TextEmbeddingParams } from '@elizaos/core';\nimport { type GenerateTextParams, ModelType, logger } from '@elizaos/core';\nimport { generateObject, generateText, embed } from 'ai';\nimport { createOllama } from 'ollama-ai-provider';\n\n// Default Ollama API URL\nconst OLLAMA_API_URL = 'http://localhost:11434/api';\n\n/**\n * Retrieves the Ollama API base URL from runtime settings.\n *\n * If the API endpoint is not set in the runtime, defaults to the standard Ollama URL.\n * The URL should include the /api path for ollama-ai-provider compatibility.\n *\n * @returns The base URL for the Ollama API.\n */\nfunction getBaseURL(runtime: { getSetting: (key: string) => string | undefined }): string {\n  const apiEndpoint =\n    runtime.getSetting('OLLAMA_API_ENDPOINT') ||\n    runtime.getSetting('OLLAMA_API_URL') ||\n    OLLAMA_API_URL;\n\n  // Ensure the URL ends with /api for ollama-ai-provider\n  if (!apiEndpoint.endsWith('/api')) {\n    return apiEndpoint.endsWith('/') ? `${apiEndpoint}api` : `${apiEndpoint}/api`;\n  }\n  return apiEndpoint;\n}\n\n/**\n * Ensures that the specified Ollama model is available locally, downloading it if necessary.\n *\n * Checks for the presence of the model via the Ollama API and attempts to download it if not found. Logs progress and errors during the process.\n */\nasync function ensureModelAvailable(\n  runtime: {\n    getSetting: (key: string) => string | undefined;\n    fetch?: typeof fetch;\n  },\n  model: string,\n  providedBaseURL?: string\n) {\n  const baseURL = providedBaseURL || getBaseURL(runtime);\n  // Remove /api suffix for direct API calls\n  const apiBase = baseURL.endsWith('/api') ? baseURL.slice(0, -4) : baseURL;\n  try {\n    const showRes = await fetch(`${apiBase}/api/show`, {\n      method: 'POST',\n      headers: { 'Content-Type': 'application/json' },\n      body: JSON.stringify({ model }),\n    });\n    if (showRes.ok) return;\n    logger.info(`[Ollama] Model ${model} not found locally. Downloading...`);\n    const pullRes = await fetch(`${apiBase}/api/pull`, {\n      method: 'POST',\n      headers: { 'Content-Type': 'application/json' },\n      body: JSON.stringify({ model, stream: false }),\n    });\n    if (!pullRes.ok) {\n      logger.error(`Failed to pull model ${model}: ${pullRes.statusText}`);\n    } else {\n      logger.info(`[Ollama] Downloaded model ${model}`);\n    }\n  } catch (err) {\n    logger.error({ error: err }, 'Error ensuring model availability');\n  }\n}\n\n/**\n * Generates text from the Ollama API using the specified model and parameters.\n *\n * Returns the generated text, or an error message if generation fails.\n */\nasync function generateOllamaText(\n  ollama: ReturnType<typeof createOllama>,\n  model: string,\n  params: {\n    prompt: string;\n    system?: string;\n    temperature: number;\n    maxTokens: number;\n    frequencyPenalty: number;\n    presencePenalty: number;\n    stopSequences: string[];\n  }\n) {\n  try {\n    const { text: ollamaResponse } = await generateText({\n      model: ollama(model),\n      prompt: params.prompt,\n      system: params.system,\n      temperature: params.temperature,\n      maxTokens: params.maxTokens,\n      frequencyPenalty: params.frequencyPenalty,\n      presencePenalty: params.presencePenalty,\n      stopSequences: params.stopSequences,\n    });\n    return ollamaResponse;\n  } catch (error: unknown) {\n    logger.error({ error }, 'Error in generateOllamaText');\n    return 'Error generating text. Please try again later.';\n  }\n}\n\n/**\n * Generates an object from the Ollama API using the specified model and parameters.\n *\n * Returns the generated object, or an empty object if generation fails.\n */\nasync function generateOllamaObject(\n  ollama: ReturnType<typeof createOllama>,\n  model: string,\n  params: ObjectGenerationParams\n) {\n  try {\n    const { object } = await generateObject({\n      model: ollama(model),\n      output: 'no-schema',\n      prompt: params.prompt,\n      temperature: params.temperature,\n    });\n    return object;\n  } catch (error: unknown) {\n    logger.error({ error }, 'Error generating object');\n    return {};\n  }\n}\n\nexport const ollamaPlugin: Plugin = {\n  name: 'ollama',\n  description: 'Ollama plugin',\n  config: {\n    OLLAMA_API_ENDPOINT: process.env.OLLAMA_API_ENDPOINT,\n    OLLAMA_SMALL_MODEL: process.env.OLLAMA_SMALL_MODEL,\n    OLLAMA_MEDIUM_MODEL: process.env.OLLAMA_MEDIUM_MODEL,\n    OLLAMA_LARGE_MODEL: process.env.OLLAMA_LARGE_MODEL,\n    OLLAMA_EMBEDDING_MODEL: process.env.OLLAMA_EMBEDDING_MODEL,\n  },\n  async init(_config, runtime) {\n    const baseURL = getBaseURL(runtime);\n\n    // Check if endpoint is configured\n    if (!baseURL || baseURL === 'http://localhost:11434/api') {\n      const endpoint = runtime.getSetting('OLLAMA_API_ENDPOINT');\n      if (!endpoint) {\n        logger.warn(\n          'OLLAMA_API_ENDPOINT is not set in environment - Ollama functionality will use default localhost:11434'\n        );\n      }\n    }\n\n    try {\n      // Validate Ollama API endpoint by checking if it's accessible\n      // Remove /api suffix for direct API calls\n      const apiBase = baseURL.endsWith('/api') ? baseURL.slice(0, -4) : baseURL;\n      const response = await fetch(`${apiBase}/api/tags`, {\n        method: 'GET',\n        headers: { 'Content-Type': 'application/json' },\n      });\n\n      if (!response.ok) {\n        logger.warn(`Ollama API endpoint validation failed: ${response.statusText}`);\n        logger.warn('Ollama functionality will be limited until a valid endpoint is provided');\n      } else {\n        const data = (await response.json()) as {\n          models?: Array<{ name: string }>;\n        };\n        const modelCount = data?.models?.length || 0;\n        logger.log(\n          `Ollama API endpoint validated successfully. Found ${modelCount} models available.`\n        );\n      }\n    } catch (fetchError: unknown) {\n      const message = fetchError instanceof Error ? fetchError.message : String(fetchError);\n      logger.warn(`Error validating Ollama API endpoint: ${message}`);\n      logger.warn(\n        'Ollama functionality will be limited until a valid endpoint is provided - Make sure Ollama is running at ${baseURL}'\n      );\n    }\n  },\n  models: {\n    [ModelType.TEXT_EMBEDDING]: async (\n      runtime,\n      params: TextEmbeddingParams | string | null\n    ): Promise<number[]> => {\n      try {\n        const baseURL = getBaseURL(runtime);\n        const ollama = createOllama({\n          fetch: runtime.fetch,\n          baseURL,\n        });\n\n        const modelName = runtime.getSetting('OLLAMA_EMBEDDING_MODEL') || 'nomic-embed-text:latest';\n        logger.log(`[Ollama] Using TEXT_EMBEDDING model: ${modelName}`);\n        await ensureModelAvailable(runtime, modelName, baseURL);\n        const text =\n          typeof params === 'string'\n            ? params\n            : params\n              ? (params as TextEmbeddingParams).text || ''\n              : '';\n\n        // If no text is provided (e.g., for dimension detection), use a default text\n        const embeddingText = text || 'test';\n\n        if (!text) {\n          logger.debug(\n            'No text provided for embedding, using default text for dimension detection'\n          );\n        }\n\n        // Use ollama.embedding() as shown in the docs\n        try {\n          const { embedding } = await embed({\n            model: ollama.embedding(modelName),\n            value: embeddingText,\n          });\n          return embedding;\n        } catch (embeddingError) {\n          logger.error({ error: embeddingError }, 'Error generating embedding');\n          return Array(1536).fill(0);\n        }\n      } catch (error) {\n        logger.error({ error }, 'Error in TEXT_EMBEDDING model');\n        // Return a fallback vector rather than crashing\n        return Array(1536).fill(0);\n      }\n    },\n    [ModelType.TEXT_SMALL]: async (runtime, { prompt, stopSequences = [] }: GenerateTextParams) => {\n      try {\n        const temperature = 0.7;\n        const frequency_penalty = 0.7;\n        const presence_penalty = 0.7;\n        const max_response_length = 8000;\n        const baseURL = getBaseURL(runtime);\n        const ollama = createOllama({\n          fetch: runtime.fetch,\n          baseURL,\n        });\n\n        const model =\n          runtime.getSetting('OLLAMA_SMALL_MODEL') ||\n          runtime.getSetting('SMALL_MODEL') ||\n          'gemma3:latest';\n\n        logger.log(`[Ollama] Using TEXT_SMALL model: ${model}`);\n        await ensureModelAvailable(runtime, model, baseURL);\n        logger.log('generating text');\n        logger.log(prompt);\n\n        return await generateOllamaText(ollama, model, {\n          prompt,\n          system: runtime.character?.system || undefined,\n          temperature,\n          maxTokens: max_response_length,\n          frequencyPenalty: frequency_penalty,\n          presencePenalty: presence_penalty,\n          stopSequences,\n        });\n      } catch (error) {\n        logger.error({ error }, 'Error in TEXT_SMALL model');\n        return 'Error generating text. Please try again later.';\n      }\n    },\n    [ModelType.TEXT_LARGE]: async (\n      runtime,\n      {\n        prompt,\n        stopSequences = [],\n        maxTokens = 8192,\n        temperature = 0.7,\n        frequencyPenalty = 0.7,\n        presencePenalty = 0.7,\n      }: GenerateTextParams\n    ) => {\n      try {\n        const model =\n          runtime.getSetting('OLLAMA_LARGE_MODEL') ||\n          runtime.getSetting('LARGE_MODEL') ||\n          'gemma3:latest';\n        const baseURL = getBaseURL(runtime);\n        const ollama = createOllama({\n          fetch: runtime.fetch,\n          baseURL,\n        });\n\n        logger.log(`[Ollama] Using TEXT_LARGE model: ${model}`);\n        await ensureModelAvailable(runtime, model, baseURL);\n        return await generateOllamaText(ollama, model, {\n          prompt,\n          system: runtime.character?.system || undefined,\n          temperature,\n          maxTokens,\n          frequencyPenalty,\n          presencePenalty,\n          stopSequences,\n        });\n      } catch (error) {\n        logger.error({ error }, 'Error in TEXT_LARGE model');\n        return 'Error generating text. Please try again later.';\n      }\n    },\n    [ModelType.OBJECT_SMALL]: async (runtime, params: ObjectGenerationParams) => {\n      try {\n        const baseURL = getBaseURL(runtime);\n        const ollama = createOllama({\n          fetch: runtime.fetch,\n          baseURL,\n        });\n        const model =\n          runtime.getSetting('OLLAMA_SMALL_MODEL') ||\n          runtime.getSetting('SMALL_MODEL') ||\n          'gemma3:latest';\n\n        logger.log(`[Ollama] Using OBJECT_SMALL model: ${model}`);\n        await ensureModelAvailable(runtime, model, baseURL);\n        if (params.schema) {\n          logger.info('Using OBJECT_SMALL without schema validation');\n        }\n\n        return await generateOllamaObject(ollama, model, params);\n      } catch (error) {\n        logger.error({ error }, 'Error in OBJECT_SMALL model');\n        // Return empty object instead of crashing\n        return {};\n      }\n    },\n    [ModelType.OBJECT_LARGE]: async (runtime, params: ObjectGenerationParams) => {\n      try {\n        const baseURL = getBaseURL(runtime);\n        const ollama = createOllama({\n          fetch: runtime.fetch,\n          baseURL,\n        });\n        const model =\n          runtime.getSetting('OLLAMA_LARGE_MODEL') ||\n          runtime.getSetting('LARGE_MODEL') ||\n          'gemma3:latest';\n\n        logger.log(`[Ollama] Using OBJECT_LARGE model: ${model}`);\n        await ensureModelAvailable(runtime, model, baseURL);\n        if (params.schema) {\n          logger.info('Using OBJECT_LARGE without schema validation');\n        }\n\n        return await generateOllamaObject(ollama, model, params);\n      } catch (error) {\n        logger.error({ error }, 'Error in OBJECT_LARGE model');\n        // Return empty object instead of crashing\n        return {};\n      }\n    },\n  },\n  tests: [\n    {\n      name: 'ollama_plugin_tests',\n      tests: [\n        {\n          name: 'ollama_test_url_validation',\n          fn: async (runtime) => {\n            try {\n              const baseURL = getBaseURL(runtime);\n              // Remove /api suffix for direct API calls\n              const apiBase = baseURL.endsWith('/api') ? baseURL.slice(0, -4) : baseURL;\n              const response = await fetch(`${apiBase}/api/tags`);\n              const data = await response.json();\n              const modelCount =\n                data && typeof data === 'object' && 'models' in data && Array.isArray(data.models)\n                  ? data.models.length\n                  : 0;\n              logger.log(`Models Available: ${modelCount}`);\n              if (!response.ok) {\n                logger.error(`Failed to validate Ollama API: ${response.statusText}`);\n                return;\n              }\n            } catch (error) {\n              logger.error({ error }, 'Error in ollama_test_url_validation');\n            }\n          },\n        },\n        {\n          name: 'ollama_test_text_embedding',\n          fn: async (runtime) => {\n            try {\n              const embedding = await runtime.useModel(ModelType.TEXT_EMBEDDING, {\n                text: 'Hello, world!',\n              });\n              logger.log({ embedding }, 'Generated embedding');\n            } catch (error) {\n              logger.error({ error }, 'Error in test_text_embedding');\n            }\n          },\n        },\n        {\n          name: 'ollama_test_text_large',\n          fn: async (runtime) => {\n            try {\n              const text = await runtime.useModel(ModelType.TEXT_LARGE, {\n                prompt: 'What is the nature of reality in 10 words?',\n              });\n              if (text.length === 0) {\n                logger.error('Failed to generate text');\n                return;\n              }\n              logger.log({ text }, 'Generated with test_text_large');\n            } catch (error) {\n              logger.error({ error }, 'Error in test_text_large');\n            }\n          },\n        },\n        {\n          name: 'ollama_test_text_small',\n          fn: async (runtime) => {\n            try {\n              const text = await runtime.useModel(ModelType.TEXT_SMALL, {\n                prompt: 'What is the nature of reality in 10 words?',\n              });\n              if (text.length === 0) {\n                logger.error('Failed to generate text');\n                return;\n              }\n              logger.log({ text }, 'Generated with test_text_small');\n            } catch (error) {\n              logger.error({ error }, 'Error in test_text_small');\n            }\n          },\n        },\n        {\n          name: 'ollama_test_object_small',\n          fn: async (runtime) => {\n            try {\n              const object = await runtime.useModel(ModelType.OBJECT_SMALL, {\n                prompt:\n                  'Generate a JSON object representing a user profile with name, age, and hobbies',\n                temperature: 0.7,\n                schema: undefined,\n              });\n              logger.log({ object }, 'Generated object');\n            } catch (error) {\n              logger.error({ error }, 'Error in test_object_small');\n            }\n          },\n        },\n        {\n          name: 'ollama_test_object_large',\n          fn: async (runtime) => {\n            try {\n              const object = await runtime.useModel(ModelType.OBJECT_LARGE, {\n                prompt:\n                  'Generate a detailed JSON object representing a restaurant with name, cuisine type, menu items with prices, and customer reviews',\n                temperature: 0.7,\n                schema: undefined,\n              });\n              logger.log({ object }, 'Generated object');\n            } catch (error) {\n              logger.error({ error }, 'Error in test_object_large');\n            }\n          },\n        },\n      ],\n    },\n  ],\n};\nexport default ollamaPlugin;\n"],"mappings":";AACA,SAAkC,WAAW,cAAc;AAC3D,SAAS,gBAAgB,cAAc,aAAa;AACpD,SAAS,oBAAoB;AAG7B,IAAM,iBAAiB;AAUvB,SAAS,WAAW,SAAsE;AACxF,QAAM,cACJ,QAAQ,WAAW,qBAAqB,KACxC,QAAQ,WAAW,gBAAgB,KACnC;AAGF,MAAI,CAAC,YAAY,SAAS,MAAM,GAAG;AACjC,WAAO,YAAY,SAAS,GAAG,IAAI,GAAG,WAAW,QAAQ,GAAG,WAAW;AAAA,EACzE;AACA,SAAO;AACT;AAOA,eAAe,qBACb,SAIA,OACA,iBACA;AACA,QAAM,UAAU,mBAAmB,WAAW,OAAO;AAErD,QAAM,UAAU,QAAQ,SAAS,MAAM,IAAI,QAAQ,MAAM,GAAG,EAAE,IAAI;AAClE,MAAI;AACF,UAAM,UAAU,MAAM,MAAM,GAAG,OAAO,aAAa;AAAA,MACjD,QAAQ;AAAA,MACR,SAAS,EAAE,gBAAgB,mBAAmB;AAAA,MAC9C,MAAM,KAAK,UAAU,EAAE,MAAM,CAAC;AAAA,IAChC,CAAC;AACD,QAAI,QAAQ,GAAI;AAChB,WAAO,KAAK,kBAAkB,KAAK,oCAAoC;AACvE,UAAM,UAAU,MAAM,MAAM,GAAG,OAAO,aAAa;AAAA,MACjD,QAAQ;AAAA,MACR,SAAS,EAAE,gBAAgB,mBAAmB;AAAA,MAC9C,MAAM,KAAK,UAAU,EAAE,OAAO,QAAQ,MAAM,CAAC;AAAA,IAC/C,CAAC;AACD,QAAI,CAAC,QAAQ,IAAI;AACf,aAAO,MAAM,wBAAwB,KAAK,KAAK,QAAQ,UAAU,EAAE;AAAA,IACrE,OAAO;AACL,aAAO,KAAK,6BAA6B,KAAK,EAAE;AAAA,IAClD;AAAA,EACF,SAAS,KAAK;AACZ,WAAO,MAAM,EAAE,OAAO,IAAI,GAAG,mCAAmC;AAAA,EAClE;AACF;AAOA,eAAe,mBACb,QACA,OACA,QASA;AACA,MAAI;AACF,UAAM,EAAE,MAAM,eAAe,IAAI,MAAM,aAAa;AAAA,MAClD,OAAO,OAAO,KAAK;AAAA,MACnB,QAAQ,OAAO;AAAA,MACf,QAAQ,OAAO;AAAA,MACf,aAAa,OAAO;AAAA,MACpB,WAAW,OAAO;AAAA,MAClB,kBAAkB,OAAO;AAAA,MACzB,iBAAiB,OAAO;AAAA,MACxB,eAAe,OAAO;AAAA,IACxB,CAAC;AACD,WAAO;AAAA,EACT,SAAS,OAAgB;AACvB,WAAO,MAAM,EAAE,MAAM,GAAG,6BAA6B;AACrD,WAAO;AAAA,EACT;AACF;AAOA,eAAe,qBACb,QACA,OACA,QACA;AACA,MAAI;AACF,UAAM,EAAE,OAAO,IAAI,MAAM,eAAe;AAAA,MACtC,OAAO,OAAO,KAAK;AAAA,MACnB,QAAQ;AAAA,MACR,QAAQ,OAAO;AAAA,MACf,aAAa,OAAO;AAAA,IACtB,CAAC;AACD,WAAO;AAAA,EACT,SAAS,OAAgB;AACvB,WAAO,MAAM,EAAE,MAAM,GAAG,yBAAyB;AACjD,WAAO,CAAC;AAAA,EACV;AACF;AAEO,IAAM,eAAuB;AAAA,EAClC,MAAM;AAAA,EACN,aAAa;AAAA,EACb,QAAQ;AAAA,IACN,qBAAqB,QAAQ,IAAI;AAAA,IACjC,oBAAoB,QAAQ,IAAI;AAAA,IAChC,qBAAqB,QAAQ,IAAI;AAAA,IACjC,oBAAoB,QAAQ,IAAI;AAAA,IAChC,wBAAwB,QAAQ,IAAI;AAAA,EACtC;AAAA,EACA,MAAM,KAAK,SAAS,SAAS;AAC3B,UAAM,UAAU,WAAW,OAAO;AAGlC,QAAI,CAAC,WAAW,YAAY,8BAA8B;AACxD,YAAM,WAAW,QAAQ,WAAW,qBAAqB;AACzD,UAAI,CAAC,UAAU;AACb,eAAO;AAAA,UACL;AAAA,QACF;AAAA,MACF;AAAA,IACF;AAEA,QAAI;AAGF,YAAM,UAAU,QAAQ,SAAS,MAAM,IAAI,QAAQ,MAAM,GAAG,EAAE,IAAI;AAClE,YAAM,WAAW,MAAM,MAAM,GAAG,OAAO,aAAa;AAAA,QAClD,QAAQ;AAAA,QACR,SAAS,EAAE,gBAAgB,mBAAmB;AAAA,MAChD,CAAC;AAED,UAAI,CAAC,SAAS,IAAI;AAChB,eAAO,KAAK,0CAA0C,SAAS,UAAU,EAAE;AAC3E,eAAO,KAAK,yEAAyE;AAAA,MACvF,OAAO;AACL,cAAM,OAAQ,MAAM,SAAS,KAAK;AAGlC,cAAM,aAAa,MAAM,QAAQ,UAAU;AAC3C,eAAO;AAAA,UACL,qDAAqD,UAAU;AAAA,QACjE;AAAA,MACF;AAAA,IACF,SAAS,YAAqB;AAC5B,YAAM,UAAU,sBAAsB,QAAQ,WAAW,UAAU,OAAO,UAAU;AACpF,aAAO,KAAK,yCAAyC,OAAO,EAAE;AAC9D,aAAO;AAAA,QACL;AAAA,MACF;AAAA,IACF;AAAA,EACF;AAAA,EACA,QAAQ;AAAA,IACN,CAAC,UAAU,cAAc,GAAG,OAC1B,SACA,WACsB;AACtB,UAAI;AACF,cAAM,UAAU,WAAW,OAAO;AAClC,cAAM,SAAS,aAAa;AAAA,UAC1B,OAAO,QAAQ;AAAA,UACf;AAAA,QACF,CAAC;AAED,cAAM,YAAY,QAAQ,WAAW,wBAAwB,KAAK;AAClE,eAAO,IAAI,wCAAwC,SAAS,EAAE;AAC9D,cAAM,qBAAqB,SAAS,WAAW,OAAO;AACtD,cAAM,OACJ,OAAO,WAAW,WACd,SACA,SACG,OAA+B,QAAQ,KACxC;AAGR,cAAM,gBAAgB,QAAQ;AAE9B,YAAI,CAAC,MAAM;AACT,iBAAO;AAAA,YACL;AAAA,UACF;AAAA,QACF;AAGA,YAAI;AACF,gBAAM,EAAE,UAAU,IAAI,MAAM,MAAM;AAAA,YAChC,OAAO,OAAO,UAAU,SAAS;AAAA,YACjC,OAAO;AAAA,UACT,CAAC;AACD,iBAAO;AAAA,QACT,SAAS,gBAAgB;AACvB,iBAAO,MAAM,EAAE,OAAO,eAAe,GAAG,4BAA4B;AACpE,iBAAO,MAAM,IAAI,EAAE,KAAK,CAAC;AAAA,QAC3B;AAAA,MACF,SAAS,OAAO;AACd,eAAO,MAAM,EAAE,MAAM,GAAG,+BAA+B;AAEvD,eAAO,MAAM,IAAI,EAAE,KAAK,CAAC;AAAA,MAC3B;AAAA,IACF;AAAA,IACA,CAAC,UAAU,UAAU,GAAG,OAAO,SAAS,EAAE,QAAQ,gBAAgB,CAAC,EAAE,MAA0B;AAC7F,UAAI;AACF,cAAM,cAAc;AACpB,cAAM,oBAAoB;AAC1B,cAAM,mBAAmB;AACzB,cAAM,sBAAsB;AAC5B,cAAM,UAAU,WAAW,OAAO;AAClC,cAAM,SAAS,aAAa;AAAA,UAC1B,OAAO,QAAQ;AAAA,UACf;AAAA,QACF,CAAC;AAED,cAAM,QACJ,QAAQ,WAAW,oBAAoB,KACvC,QAAQ,WAAW,aAAa,KAChC;AAEF,eAAO,IAAI,oCAAoC,KAAK,EAAE;AACtD,cAAM,qBAAqB,SAAS,OAAO,OAAO;AAClD,eAAO,IAAI,iBAAiB;AAC5B,eAAO,IAAI,MAAM;AAEjB,eAAO,MAAM,mBAAmB,QAAQ,OAAO;AAAA,UAC7C;AAAA,UACA,QAAQ,QAAQ,WAAW,UAAU;AAAA,UACrC;AAAA,UACA,WAAW;AAAA,UACX,kBAAkB;AAAA,UAClB,iBAAiB;AAAA,UACjB;AAAA,QACF,CAAC;AAAA,MACH,SAAS,OAAO;AACd,eAAO,MAAM,EAAE,MAAM,GAAG,2BAA2B;AACnD,eAAO;AAAA,MACT;AAAA,IACF;AAAA,IACA,CAAC,UAAU,UAAU,GAAG,OACtB,SACA;AAAA,MACE;AAAA,MACA,gBAAgB,CAAC;AAAA,MACjB,YAAY;AAAA,MACZ,cAAc;AAAA,MACd,mBAAmB;AAAA,MACnB,kBAAkB;AAAA,IACpB,MACG;AACH,UAAI;AACF,cAAM,QACJ,QAAQ,WAAW,oBAAoB,KACvC,QAAQ,WAAW,aAAa,KAChC;AACF,cAAM,UAAU,WAAW,OAAO;AAClC,cAAM,SAAS,aAAa;AAAA,UAC1B,OAAO,QAAQ;AAAA,UACf;AAAA,QACF,CAAC;AAED,eAAO,IAAI,oCAAoC,KAAK,EAAE;AACtD,cAAM,qBAAqB,SAAS,OAAO,OAAO;AAClD,eAAO,MAAM,mBAAmB,QAAQ,OAAO;AAAA,UAC7C;AAAA,UACA,QAAQ,QAAQ,WAAW,UAAU;AAAA,UACrC;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,QACF,CAAC;AAAA,MACH,SAAS,OAAO;AACd,eAAO,MAAM,EAAE,MAAM,GAAG,2BAA2B;AACnD,eAAO;AAAA,MACT;AAAA,IACF;AAAA,IACA,CAAC,UAAU,YAAY,GAAG,OAAO,SAAS,WAAmC;AAC3E,UAAI;AACF,cAAM,UAAU,WAAW,OAAO;AAClC,cAAM,SAAS,aAAa;AAAA,UAC1B,OAAO,QAAQ;AAAA,UACf;AAAA,QACF,CAAC;AACD,cAAM,QACJ,QAAQ,WAAW,oBAAoB,KACvC,QAAQ,WAAW,aAAa,KAChC;AAEF,eAAO,IAAI,sCAAsC,KAAK,EAAE;AACxD,cAAM,qBAAqB,SAAS,OAAO,OAAO;AAClD,YAAI,OAAO,QAAQ;AACjB,iBAAO,KAAK,8CAA8C;AAAA,QAC5D;AAEA,eAAO,MAAM,qBAAqB,QAAQ,OAAO,MAAM;AAAA,MACzD,SAAS,OAAO;AACd,eAAO,MAAM,EAAE,MAAM,GAAG,6BAA6B;AAErD,eAAO,CAAC;AAAA,MACV;AAAA,IACF;AAAA,IACA,CAAC,UAAU,YAAY,GAAG,OAAO,SAAS,WAAmC;AAC3E,UAAI;AACF,cAAM,UAAU,WAAW,OAAO;AAClC,cAAM,SAAS,aAAa;AAAA,UAC1B,OAAO,QAAQ;AAAA,UACf;AAAA,QACF,CAAC;AACD,cAAM,QACJ,QAAQ,WAAW,oBAAoB,KACvC,QAAQ,WAAW,aAAa,KAChC;AAEF,eAAO,IAAI,sCAAsC,KAAK,EAAE;AACxD,cAAM,qBAAqB,SAAS,OAAO,OAAO;AAClD,YAAI,OAAO,QAAQ;AACjB,iBAAO,KAAK,8CAA8C;AAAA,QAC5D;AAEA,eAAO,MAAM,qBAAqB,QAAQ,OAAO,MAAM;AAAA,MACzD,SAAS,OAAO;AACd,eAAO,MAAM,EAAE,MAAM,GAAG,6BAA6B;AAErD,eAAO,CAAC;AAAA,MACV;AAAA,IACF;AAAA,EACF;AAAA,EACA,OAAO;AAAA,IACL;AAAA,MACE,MAAM;AAAA,MACN,OAAO;AAAA,QACL;AAAA,UACE,MAAM;AAAA,UACN,IAAI,OAAO,YAAY;AACrB,gBAAI;AACF,oBAAM,UAAU,WAAW,OAAO;AAElC,oBAAM,UAAU,QAAQ,SAAS,MAAM,IAAI,QAAQ,MAAM,GAAG,EAAE,IAAI;AAClE,oBAAM,WAAW,MAAM,MAAM,GAAG,OAAO,WAAW;AAClD,oBAAM,OAAO,MAAM,SAAS,KAAK;AACjC,oBAAM,aACJ,QAAQ,OAAO,SAAS,YAAY,YAAY,QAAQ,MAAM,QAAQ,KAAK,MAAM,IAC7E,KAAK,OAAO,SACZ;AACN,qBAAO,IAAI,qBAAqB,UAAU,EAAE;AAC5C,kBAAI,CAAC,SAAS,IAAI;AAChB,uBAAO,MAAM,kCAAkC,SAAS,UAAU,EAAE;AACpE;AAAA,cACF;AAAA,YACF,SAAS,OAAO;AACd,qBAAO,MAAM,EAAE,MAAM,GAAG,qCAAqC;AAAA,YAC/D;AAAA,UACF;AAAA,QACF;AAAA,QACA;AAAA,UACE,MAAM;AAAA,UACN,IAAI,OAAO,YAAY;AACrB,gBAAI;AACF,oBAAM,YAAY,MAAM,QAAQ,SAAS,UAAU,gBAAgB;AAAA,gBACjE,MAAM;AAAA,cACR,CAAC;AACD,qBAAO,IAAI,EAAE,UAAU,GAAG,qBAAqB;AAAA,YACjD,SAAS,OAAO;AACd,qBAAO,MAAM,EAAE,MAAM,GAAG,8BAA8B;AAAA,YACxD;AAAA,UACF;AAAA,QACF;AAAA,QACA;AAAA,UACE,MAAM;AAAA,UACN,IAAI,OAAO,YAAY;AACrB,gBAAI;AACF,oBAAM,OAAO,MAAM,QAAQ,SAAS,UAAU,YAAY;AAAA,gBACxD,QAAQ;AAAA,cACV,CAAC;AACD,kBAAI,KAAK,WAAW,GAAG;AACrB,uBAAO,MAAM,yBAAyB;AACtC;AAAA,cACF;AACA,qBAAO,IAAI,EAAE,KAAK,GAAG,gCAAgC;AAAA,YACvD,SAAS,OAAO;AACd,qBAAO,MAAM,EAAE,MAAM,GAAG,0BAA0B;AAAA,YACpD;AAAA,UACF;AAAA,QACF;AAAA,QACA;AAAA,UACE,MAAM;AAAA,UACN,IAAI,OAAO,YAAY;AACrB,gBAAI;AACF,oBAAM,OAAO,MAAM,QAAQ,SAAS,UAAU,YAAY;AAAA,gBACxD,QAAQ;AAAA,cACV,CAAC;AACD,kBAAI,KAAK,WAAW,GAAG;AACrB,uBAAO,MAAM,yBAAyB;AACtC;AAAA,cACF;AACA,qBAAO,IAAI,EAAE,KAAK,GAAG,gCAAgC;AAAA,YACvD,SAAS,OAAO;AACd,qBAAO,MAAM,EAAE,MAAM,GAAG,0BAA0B;AAAA,YACpD;AAAA,UACF;AAAA,QACF;AAAA,QACA;AAAA,UACE,MAAM;AAAA,UACN,IAAI,OAAO,YAAY;AACrB,gBAAI;AACF,oBAAM,SAAS,MAAM,QAAQ,SAAS,UAAU,cAAc;AAAA,gBAC5D,QACE;AAAA,gBACF,aAAa;AAAA,gBACb,QAAQ;AAAA,cACV,CAAC;AACD,qBAAO,IAAI,EAAE,OAAO,GAAG,kBAAkB;AAAA,YAC3C,SAAS,OAAO;AACd,qBAAO,MAAM,EAAE,MAAM,GAAG,4BAA4B;AAAA,YACtD;AAAA,UACF;AAAA,QACF;AAAA,QACA;AAAA,UACE,MAAM;AAAA,UACN,IAAI,OAAO,YAAY;AACrB,gBAAI;AACF,oBAAM,SAAS,MAAM,QAAQ,SAAS,UAAU,cAAc;AAAA,gBAC5D,QACE;AAAA,gBACF,aAAa;AAAA,gBACb,QAAQ;AAAA,cACV,CAAC;AACD,qBAAO,IAAI,EAAE,OAAO,GAAG,kBAAkB;AAAA,YAC3C,SAAS,OAAO;AACd,qBAAO,MAAM,EAAE,MAAM,GAAG,4BAA4B;AAAA,YACtD;AAAA,UACF;AAAA,QACF;AAAA,MACF;AAAA,IACF;AAAA,EACF;AACF;AACA,IAAO,gBAAQ;","names":[]}